{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from gym.envs.registration import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME_STEPS = 100\n",
    "\n",
    "register(\n",
    "    id='FrozenLakeNotSlippery-v0',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "    max_episode_steps=MAX_TIME_STEPS,\n",
    "    reward_threshold=0.8196, # optimum = .8196, changing this seems have no influence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLakeNotSlippery-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros((env.observation_space.n, env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 9587.69it/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_EPISODES = 10000\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT_RATE = 0.9\n",
    "epsilon = 1\n",
    "\n",
    "# def get_action(observation, epsilon):\n",
    "#     rn = random.uniform(0,1)\n",
    "#     if rn > epsilon:\n",
    "#         # do exploitation\n",
    "#         if np.where(q_table[observation] == 0)[0].sum() == env.action_space.n: action = env.action_space.sample()\n",
    "#         else: action = np.argmax(q_table[observation])\n",
    "#     else:\n",
    "#         # do exploration\n",
    "#         action = env.action_space.sample()\n",
    "#     return action\n",
    "\n",
    "def exploration_action():\n",
    "    return env.action_space.sample()\n",
    "\n",
    "def exploitation_action(observation):\n",
    "    return np.argmax(q_table[observation])\n",
    "\n",
    "def update_q_table(q_table, cur_ob, new_ob, action, reward):\n",
    "    # apply belmann equation\n",
    "    q_table[cur_ob, action] = q_table[cur_ob, action] + LEARNING_RATE*(reward + DISCOUNT_RATE*(np.max(q_table[new_ob])) - q_table[cur_ob, action])\n",
    "    return q_table\n",
    "    \n",
    "for i_episode in tqdm(range(NUM_EPISODES),total=NUM_EPISODES):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        action = exploration_action()\n",
    "        cur_ob = observation\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        update_q_table(q_table, cur_ob, observation, action, reward)\n",
    "        if done : \n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53144084, 0.59048982, 0.5904898 , 0.53144083],\n",
       "       [0.53144083, 0.        , 0.65609978, 0.59048979],\n",
       "       [0.59048978, 0.72899977, 0.59048975, 0.65609977],\n",
       "       [0.65609975, 0.        , 0.59048968, 0.59048972],\n",
       "       [0.5904898 , 0.6560998 , 0.        , 0.53144083],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.8099998 , 0.        , 0.65609959],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.65609977, 0.        , 0.72899979, 0.5904898 ],\n",
       "       [0.65609972, 0.80999958, 0.80999983, 0.        ],\n",
       "       [0.72899946, 0.89999989, 0.        , 0.72899948],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.80999789, 0.89999967, 0.72899862],\n",
       "       [0.80998849, 0.89999865, 0.99999996, 0.80999712],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        action = exploitation_action(observation)\n",
    "        cur_ob = observation\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done : \n",
    "            print('Episode ended after {} timesteps...'.format(t+1))\n",
    "            break\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Episode ended after 6 timesteps...\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
